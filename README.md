# ğŸ§  Ollama4Truth

**Ollama4Truth** is an open-source framework for **misinformation detection and fact-checking** using **Large Language Models (LLMs)** through the [Ollama](https://ollama.com) ecosystem.

This project aims to explore, evaluate, and democratize the use of open-source LLMs for identifying and mitigating online disinformation â€” particularly in **Portuguese (PT-BR)** and **English** contexts.

---

## ğŸ¯ Objectives

- Develop a modular and reproducible pipeline for **fact-checking and misinformation identification**.  
- Evaluate open LLMsâ€™ capabilities in **detecting false or misleading content**.  
- Foster **open collaboration** and **transparent evaluation** within the AI research community.

---

## Configuration

1. Create a .env file:
````
OLLAMA_MODEL=llama3.1
GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY
GOOGLE_CSE_ID=YOUR_CSE_ID
````

2. Install requirements (with Python 3.10):
````
pip install -r requirements.txt
````

## ğŸš€ How to run?

1. Start the server:
````
uvicorn api:app --reload
````
---

2. Send a POST request to http://localhost:8000/analyze with the claim:
````
{
  "claim": "O cafÃ© ajuda a melhorar a memÃ³ria de longo prazo."
}
````

## âš™ï¸ Technologies

- ğŸ¦™ **[Ollama](https://ollama.com)** â€” local LLM inference  
- ğŸ” **Google Search API** â€” open evidence retrieval  
- ğŸ¤— **Transformers** â€” tokenization and model loading  
- ğŸ§® **PyTorch** â€” inference backend  
- ğŸ“„ **BM25 / FAISS** â€” ranking and document retrieval  
- ğŸ§° **Python (3.10+)**

---

## ğŸª¶ License

Released under the **MIT License** â€” free for research and open-source use.

---

